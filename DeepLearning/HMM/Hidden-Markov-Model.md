---
title: "隐马尔科夫模型"
author: "xht03"
date: 2025-05-19 15:59:10
tags:
- labs
- notes
categories:
- Deep Learning
header-includes:
- \usepackage{xeCJK}
---

## 随机过程

随机过程是一组随机变量的集合，用于描述系统在时间或空间上的随机演化。

设 $T$ 是一个参数集（通常是时间或空间），$\{X_t, t \in T\}$ 是一族随机变量，则称 $\{X_t\}$ 为一个**随机过程**。

  - 如果 $T$ 是离散的（如 $T = \{0, 1, 2, \dots\}$ ），则称为**离散时间随机过程**（如马尔可夫链）。
  
  - 如果 $T$ 是连续的（如 $T = [0, \infty)$ ），则称为**连续时间随机过程**（如布朗运动）。

此外，**状态空间（State Space）**则是指：随机变量 $X_t$ 可能的取值范围，可以是离散的（如 $\{0, 1\}$ ）或连续的（如 $\mathbb{R}$ ）。

---

## 马尔可夫随机过程

设 $\{X_t, t \in T\}$ 是随机过程，若对任意的正整数 $n$ 和 $t_1 < t_2 < \cdots < t_n \in T$ ，$P\{X_{t_1}=x_1, \cdots, X_{t_{n-1}}=x_{n-1}\}$ ，且满足：

$$
P\{X_{t_n}=x_n | X_{t_1}=x_1, \cdots, X_{t_{n-1}}=x_{n-1}\} = P\{X_{t_n}=x_n | X_{t_{n-1}}=x_{n-1}\}
$$

则称 $\{X_t\}$ 是一个**马尔可夫过程**，即未来状态只与当前状态有关，而与过去状态无关（无记忆性）。

---

## 马尔可夫链

马尔科夫链是**离散时间、离散状态**的马尔可夫过程。

其数学定义如下：

随机序列 $X_t$ ，在任意时刻 $t$ ，$X_t$ 可以处于状态 $\theta_1, \cdots, \theta_N$ ，且在任意 $t+k$ 时刻（$\forall k > 0$），$X_t$ 所处的状态为 $q_{t+k}$ 的概率只与 $X_t$ 的状态有关，而与 $t$ 时刻之前的状态无关。

也即是：

$$
P\{X_{t+k} = q_{t+k} | X_t = q_t, X_{t-1} = q_{t-1}, \cdots, X_1 = q_1\} = P\{X_{t+k} = q_{t+k} | X_t = q_t\}
$$

其中，$q_1, q_2, \cdots, q_t, q_{t+k} \in \{\theta_1, \theta_2, \cdots, \theta_N\}$。

---

对于马尔科夫链，我们通常使用**转移矩阵**来描述状态之间的转移概率。

我们定义 $P_{ij}$ 为从状态 $i$ 转移到状态 $j$ 的概率。

则我们可以定义 k 步转移概率为：

$$
P_{ij}(t, t+k) = P\{X_{t+k} = \theta_j | X_t = \theta_i\}, \quad i,j \in [1,N], t \in T
$$

上式表示：已知当在时刻 $t$ 时，系统处于状态 $\theta_i$，经过 $k$ 步后，系统转移到状态 $\theta_j$ 的概率。

当 $P_{ij}(t, t+k)$ 与 $t$ 无关时，称为**齐次马尔科夫链**。此时我们简记为：

$$
P_{ij}(t, t+k) = P_{ij}(k)
$$

当 $k=1$ 时，称为**一步转移概率**，进一步简记为 $P_{ij}$ 。

一步转移概率 $P_{ij}$ 组成的矩阵称为**转移矩阵**，记为 $A$ 。

显然多步转移概率可以通过转移矩阵的幂来计算：

$$
\text{k 步转移矩阵} = A^k
$$

---

显然，转移矩阵很大程度上描述一个马尔科夫链，但是仅靠 $P_{ij}$ 决定不了马尔科夫链的初始状态。即：通过转移矩阵 $A$ ，我们求不出概率 $P(q_1=\theta_i)$ 。

为了完整地描述马尔科夫链，我们引入**初始状态分布** $\Pi$ ：

$$
\pi_i = P(q_1 = \theta_i), \quad i \in [1,N]
$$

其中 $\sum_{i=1}^N \pi_i = 1$。

---

## 隐马尔科夫模型（HMM）

在实际中，我们遇到地问题往往比马尔科夫链所描述的更复杂，观察到的事件不一定是与状态一一对应的，而是通过一组概率分布相联系，这样的模型称为**隐马尔科夫模型（HMM）**。它是一个双重随机过程，其中之一是马尔科夫链，描述状态转移；另一个随机过程则描述状态和观察值之间之间统计对应关系。

在观察者角度，只能看到观察值，不能直接看到状态（即不同于马尔科夫链），因而称之为“隐”马尔科夫模型。

---

我们举一个“球和缸”的例子来说明 HMM 的概念。

- 设$N$个缸，每个缸中装有彩球，总共有 $M$ 种不同颜色，每个缸内不同颜色的球的多少由一组概率分布来描述。

- 根据某个初始概率分布，随机选择一个缸 $i$ ，再根据这个缸中彩色球颜色的概率分布，随机选一个球，记 $O_1$ ,再把球放回缸中。

- 根据缸的转移概率，选择下一个缸 $j$ （观测者不知道更换了缸），再根据这个缸中彩色球颜色的概率分布，随机选择一个球，记 $O_2$ ,再把球放回缸中。

- 最后，得到描述球颜色的序列 $O_1, O_2, O_3, O_4 \cdots$ ，即为观察值序列，但每次选取的缸和缸之间的转移并不能直接观察。

在这个例子中，观察者看到的只是球的颜色序列，而缸的状态是不可见的（隐状态）。而构建 HMM 的目的是通过观察到的球的颜色序列来推测幕后的缸序列。

![](https://ref.xht03.online/202505241504968.png)

---

我们可以将 HMM 定义为一个**五元组**：$ (Q, V, A, B, \pi) $ ，其中：

- $Q$ 是状态集合，$Q = \{\theta_1, \theta_2, \cdots, \theta_N\}$ 。

- $V$ 是观测值集合，$V = \{v_1, v_2, \cdots, v_M\}$ 。

- $A$ 是状态转移概率矩阵，$A = [a_{ij}]$ ，其中 $a_{ij} = P\{q_{t+1}=\theta_j | q_t=\theta_i\}$ 。

- $B$ 是观测概率矩阵，$B = [b_{ij}]$ ，其中 $b_{ij} = b_i(j) = P\{O_t=v_j | q_t=\theta_i\}$ 表示在状态 $\theta_i$ 时，观测到 $v_j$ 的概率。

- $\Pi$ 是初始状态概率分布，$\Pi = [\pi_1, \pi_2, \cdots, \pi_N]$ ，其中 $\pi_i = P\{q_1=\theta_i\}$ 。

---

隐马尔科夫模型（HMM）的主要任务是解决以下三个问题：

1. **评估问题（Evaluation）**：给定模型 $\lambda = (A, B, \pi)$ 和观测序列 $O$ ，计算 $P(O \mid \lambda)$ 。
   
   - **解决方法**：前向算法（Forward Algorithm）或后向算法（Backward Algorithm）。

2. **解码问题（Decoding）**：给定模型 $\lambda$ 和观测序列 $O$ ，找到最可能的状态序列 $Q$ 。

   - **解决方法**：维特比算法（Viterbi Algorithm）。

3. **学习问题（Learning）**：给定观测序列 $O$ ，估计模型参数 $\lambda$ 。

   - **解决方法**：鲍姆-韦尔奇算法（Baum-Welch Algorithm），即 EM 算法在 HMM 中的应用。

---

## Trellis 算法

格栅（Trellis）算法是一种用于处理 HMM 的高效算法，主要用于评估问题和解码问题。它通过构建一个网格结构（Trellis）来表示状态转移和观测序列的关系。

Trellis 算法包含以下几个主要部分：

- **前向算法**：用于计算给定模型参数时，观测序列出现的概率。

- **后向算法**：用于计算从某个状态开始到结束的观测序列的概率。

### 前向算法

1. **作用**：计算给定模型参数 $\lambda$ 时，观测序列 $O$ 出现的概率 $P(O|\lambda)$ 。  
    
2. **核心思想**：

    - 构建一个 $T \times N$ 的格栅（$T$ 为时间步，$N$ 为状态数）。

    - 每个节点 $\alpha(t,i)$ 表示：在时间 $t$ 处于状态 $i$ 并观测到 $o_1,o_2,...,o_t$ 的概率。  

3. **递推公式**：  
$$
\alpha(t,j) = \left[ \sum_{i=1}^N \alpha(t-1, i) \cdot a_{ij} \right] \cdot b_j(o_t)
$$

---

### 后向算法


1. **作用**：计算从时间 $t$ 到结束的观测概率 $P(o_{t+1},...,o_T | s_t=\theta_i)$ ，记为 $\beta_t(i)$ 。  

2. **递推公式**：

$$
\beta_t(i) = \sum_{j=1}^N a_{ij} \cdot b_j(o_{t+1}) \cdot \beta_{t+1}(j)
$$

3. **用途**：与前向算法结合用于参数学习（Baum-Welch算法）。

---

### 维特比算法

1. **作用**：找到最可能生成观测序列 $O$ 的隐藏状态序列 $Q^*$ 。

2. **关键改进**：

    - 用**最大值**替代前向算法中的**求和**，并记录路径回溯指针。

---

### 格栅结构的直观理解

- **水平轴**：时间步 $t_1, t_2, ..., t_T$（观测序列的顺序）。

- **垂直轴**：所有可能的隐藏状态 $\theta_1, \theta_2, ..., \theta_N$ 。

- **节点**：每个点 $(t, i)$ 表示在时间 $t$ 处于状态 $\theta_i$ 的概率或路径得分。

- **边**：状态转移的权重（由转移矩阵 $A$ 和发射矩阵 $B$ 决定）。  

### 前向算法 VS 维特比算法

- 前向算法：计算所有可能路径的**概率和**（用于评估 $P(O|\lambda)$ ）。

- 维特比算法：找**单条最优路径**（用于解码最可能的状态序列）。

---

## Baum-Welch 算法

Baum-Welch 算法是 HMM 的**无监督学习算法**，用于在仅知道观测序列的情况下，估计模型参数（转移矩阵、发射矩阵、初始状态分布）。它是**期望最大化（EM）算法**在 HMM 中的具体实现。

给定观察值序列 $O$ ，我们希望确定一个模型 参数 $\lambda = (A, B, \Pi)$ ，使得 $P(O|\lambda)$ 最大。

$$
P(O|\lambda) = \sum_{Q} P(O, Q|\lambda) = \sum_{Q} P(O|Q, \lambda) P(Q|\lambda)
$$

其中 $Q$ 是所有可能的隐藏状态序列。由于直接计算 $P(O\mid\lambda)$ 涉及对所有可能的 $Q$ 求和，计算复杂度 $O(N^T)$ ，不可行，Baum-Welch 算法通过 ​EM 框架间接优化它。

EM 算法保证：（假设 $\lambda^{(t)}$ 是第 $t$ 次迭代的参数）

$$
P(O|\lambda^{(t+1)}) \ge P(O|\lambda^{(t)}) \iff log P(O|\lambda^{(t+1)}) \ge log P(O|\lambda^{(t)})
$$

Baum-Welch 算法通过以下两步迭代优化参数：

1. **E步（Expectation）**：基于当前参数计算隐藏状态的期望统计量（利用前向-后向算法）。

2. **M步（Maximization）**：用期望统计量更新模型参数，最大化观测序列的似然（即最大化 $P(O|\lambda)$ ）。

---

算法步骤：

1. 初始化参数：随机初始化或启发式设置。

    - 转移矩阵 $A = [a_{ij}]$

    - 发射矩阵 $B = [b_j(k)]$

    - 初始状态分布 $\pi = [\pi_i]$

2. E步：计算期望统计量

   - 利用前向概率 $\alpha_t(i)$ 和后向概率 $\beta_t(i)$ 计算：

   - **状态概率** $\gamma_t(i)$ ：

   $$
   \gamma_t(i) = P(s_t = \theta_i \mid O, \lambda) = \frac{\alpha_t(i) \beta_t(i)}{\sum_{j=1}^N \alpha_t(j) \beta_t(j)}
   $$

   - **转移概率** $\xi_t(i,j)$ ：
   
   $$
   p_t(i,j) = P(s_t = \theta_i, s_{t+1} = \theta_j \mid O, \lambda) = \frac{\alpha_t(i) a_{ij} b_j(o_{t+1}) \beta_{t+1}(j)}{\sum_{i=1}^N \sum_{j=1}^N \alpha_t(i) a_{ij} b_j(o_{t+1}) \beta_{t+1}(j)}
   $$

3. M步：更新参数（用期望统计量重新估计参数）

   - **初始状态分布**：

   $$
   \pi_i = \gamma_1(i)
   $$

   - **转移矩阵**：

   $$
   a_{ij} = \frac{\sum_{t=1}^{T-1} \xi_t(i,j)}{\sum_{t=1}^{T-1} \gamma_t(i)}
   $$

   - **观测矩阵**：

   $$
   b_j(k) = \frac{\sum_{t=1}^T \gamma_t(j) \cdot \mathbb{I}(o_t = k)}{\sum_{t=1}^T \gamma_t(j)}
   $$

   （其中 $\mathbb{I}(o_t = k)$ 是指示函数，当 $o_t = k$ 时为 1，否则为 0）

4. 迭代与终止：

   重复 E步 和 M步，直到：

   - 对数似然 $\log P(O \mid \lambda)$ 收敛。

   - 参数变化小于阈值。




