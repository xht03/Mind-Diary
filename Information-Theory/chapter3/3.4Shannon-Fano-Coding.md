---
title: "Chapter 3: Entropy (4)"
date: 2025-03-24 14:52:10
author: "xht03"
tags:
- translation
- notes
categories:
- Information and Coding Theory
header-includes:
- \usepackage{xeCJK}
---

## 3.4 Shannon-Fano Coding

Huffman 码是最优的，但计算其平均字长可能较为繁琐。Shannon-Fano 码接近最佳，且其平均字长的估计更为简单。

首先，假设我们的信源 $S$ 的所有概率 $p_i \neq 0$ 。根据推论3.12，如果一个唯一可解码的 $r$ 进制码 $C$ 对于信源 $S$ 的平均字长 $L(C)$ 要达到下界 $H_r(S)$ ，则其字长必须满足以下条件：

$$
l_i = \log_r(1/p_i), \quad \forall i
$$

然而，这通常是不可能的，因为 $\log_r(1/p_i)$ 的值通常不是整数。在这种情况下，我们采取次优的解决方法，即：

$$
l_i = \lceil \log_r(1/p_i) \rceil, \quad \forall i
$$

其中，$\lceil x_1 \rceil = \min \{ n \in \mathbb{Z} \mid n \geq x \}$ 表示大于等于 $x$ 的最小整数。因此，$l_i$ 是唯一满足以下条件的整数：

$$
 \log_r\frac{1}{p_i} \leq l_i < \log_r\frac{1}{p_i} + 1 \tag{3.6}
$$

于是，对于每个 $i$，有 $p_i \ge r^{-l_i}$ 。将此关系对所有 $i$ 求和，我们得到：

$$
K = \sum_{i=1}^q r^{-l_i} \leq \sum_{i=1}^q p_i = 1
$$

根据定理 1.20（Kraft不等式），存在一个具有这些字长 $l_i$ 的瞬时 $r$ 进制码 $C$ 。我们将这样的码 $C$ 称为信源 $S$ 的 **Shannon-Fano 码**。需要注意的是，我们并未描述如何构造这类码，只是证明了它们的存在性。

如果我们将公式 (3.6) 乘以 $p_i$，然后对所有 $i$ 求和，得到：

$$
\sum_{i=1}^q p_i \log_r \frac{1}{p_i} \leq \sum_{i=1}^q p_i l_i < \sum_{i=1}^q p_i \left(1 + \log_r \frac{1}{p_i}\right) = 1 + \sum_{i=1}^q p_i \log_r \frac{1}{p_i}
$$

这表明：

$$
H_r(S) \leq L(C) < H_r(S) + 1 \tag{3.7}
$$

我们可以将这一论证推广到某些 $p_i = 0$ 的情形，只需令 $p_i \to 0$ （此处省略细节）。然而，取极限会影响这个不等式的"好用"，因此现在我们得到的是一个稍弱的结果：

$$
H_r(S) \leq L(C) \leq H_r(S) + 1 \tag{3.8}
$$

因此，我们证明了定理 3.16：

> **定理 3.16**  
> 对于信源 $S$ 的任意 $r$ 元 Shannon-Fano 码 $C$ ，均满足：
>
> $$ H_r(S) \leq L(C) \leq H_r(S) + 1 $$

> **推论 3.17**
> 对于信源 $S$ 的任意最优 $r$ 进制码 $D$ ，均满足：
>
> $$ H_r(S) \leq L(D) < H_r(S) + 1 $$

这意味着即使无法达到下界 $H_r(S)$ ，我们仍能找到与之足够接近的编码。

> **例 3.18**  
> 设信源 $S$ 有 5 个符号，其概率分布为 $p_i = 0.3, 0.2, 0.2, 0.2, 0.1$ （如例 2.5），因此 $1/p_i = 10/3, 5, 5, 5, 10$ 。此时 $S$ 的二元 Shannon-Fano 码 $C$ 的码长为  
> 
> $$
> l_i = \lceil \log_2 (1/p_i) \rceil = \min \{ n \in \mathbb{Z} \mid 2^n \geq 1/p_i \} = 2, 3, 3, 3, 4
> $$
>
> 其平均码长 $L(C) = \sum p_i l_i = 2.8$ 。作为对比，$S$ 的 Huffman 码 $D$ 的平均码长 $L(D) = 2.3$ （见 §2.2）。由例 3.3 可知 $H_2(S) \approx 2.246$ ，因此 $C$ 满足定理 3.16。$C$ 的效率 $\eta \approx 2.246/2.8 \approx 0.802$ ，而 $D$ 的效率 $\eta \approx 2.246/2.3 \approx 0.977$ 。  

> **例 3.19**  
> 若 $p_1 = 1$ 且对所有 $i > 1$ 有 $p_i = 0$ ，则 $H_r(S) = 0$ 。此时 $S$ 的 $r$ 元最优码 $D$ 的平均码长 $L(D) = 1$，上界 $1 + H_r(S)$ 恰好达到。

Shannon-Fano 码通常接近最优。若用于信源的扩展编码（见 §2.6），其性能将更接近最优。我们将在下一节研究信源扩展的熵，以便为 §3.6 中的证明做准备。


