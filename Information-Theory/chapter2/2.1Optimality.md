---
title: "Chapter 2: Optimal Codes (1)"
author: "xht03"
date: 2025-03-10 10:16:20
tags:
- translation
- notes
categories:
- Information and Coding Theory
---

> “少言者乃最佳之人” --《亨利五世》

在第 1 章，我们探讨了信息编码的方法，以确保**唯一可解码**或**瞬时解码**。在这两种情况下，Kraft 不等式或 McMillan 不等式都表明，我们需要使用**足够长**的编码单词。这引出了**效率**的问题：如果**编码单词过长**，则存储变得困难，传输速度也会变慢。因此，我们需要在**确保有效解码**和**保证经济性**之间找到平衡。从这一角度来看，最优的编码方案是**最优编码**（optimal codes），即**平均编码长度最短的瞬时编码**。接下来，我们将证明这类编码的存在性，并研究**Huffman 算法**的构造过程。

为了简化讨论，我们主要关注**二进制编码**（$r = 2$）的情况，同时简要介绍这些思想如何扩展到**非二进制编码**。

## 2.1 Optimality

设 $S$ 为信息源，如第 1 章所述。我们仍然假设**符号的概率分布独立于时间 $n$，且与前序符号 $X_1, \dots, X_{n-1}$ 无关**。尽管以下理论可以扩展到不满足这些条件的情况，但我们将重点关注满足这些条件的最简单情况。由于数列 $\{ p_i \}$ 形成了**概率分布**，因此：

$$
0 \leq p_i \leq 1 \quad \sum_{i=1}^{q} p_i = 1
$$

如果信息源 $S$ 的编码 $C$ 具有编码单词长度 $l_1, l_2, \dots, l_q$，则其**平均编码长度**定义为：

$$
L = L(C) = \sum_{i=1}^{q} p_i l_i
$$

显然，对于所有编码 $C$，有：$ L(C) \geq 0 $ 。为了兼顾经济性与效率，我们希望使 $L(C)$ **尽可能小**，同时保证**瞬时解码**。在给定进制数 $r$ 和概率分布 $\{ pp_i \}$ 的情况下，我们希望找到**最优 $r$ 进制编码** $C$，使 $L(C)$ 最小。这样的编码称为**最优编码**（optimal codes）或**紧凑编码**（compact codes）。

> **例 2.1**
> 设 $S$ 为每日天气的信息源（如例 1.2），假设 $S$ 的符号概率分布如下：$ p_1 = \frac{1}{4}, \quad p_2 = \frac{1}{2}, \quad p_3 = \frac{1}{4} $ 。二进制编码 $C$ 如下：$ s_1 \to 00, \quad s_2 \to 01, \quad s_3 \to 1 $ ，由于该编码是前缀码，因此它是瞬时码，且其平均编码长度为：
>
> $$
> L(C) = \frac{1}{4} \cdot 2 + \frac{1}{2} \cdot 2 + \frac{1}{4} \cdot 1 = 1.75
> $$
>
> 另一种二进制编码 $D$ 如下：$ s_1 \to 00, \quad s_2 \to 1, \quad s_3 \to 01 $ 。编码 $D$ 和编码 $C$ 用的是相同的码字，但是不同顺序。该编码同样是瞬时码，但其平均编码长度为：
>
> $$
> L(D) = \frac{1}{4} \cdot 2 + \frac{1}{2} \cdot 1 + \frac{1}{4} \cdot 2 = 1.5
> $$
>
> 因此：$ L(D) < L(C) $，可见 $D$ 的平均编码长度更短。因此，$V$ 是 $S$ 的**最优二进制编码**，即：对于 $S$ 的所有瞬时二进制编码 $C$，均有 $ L(D) \leq L(C) $。

例 2.1 说明了一个普遍规律：**通过给更频繁出现的源符号分配较短的编码词，可以减少平均编码长度**。在编码 $D$ 中，我们选择了 **$w_2 = 1$**，而不是在 $C$ 中的 **$w_2 = 01$**，从而降低了平均编码长度。这种方法能够提高编码效率。**莫尔斯电码（Morse Code）** 也采用了相同的策略：对于高频使用的字符（如 "E"、"T"），使用较短的编码，而对于低频字符（如 "Q"、"Z"），使用较长的编码，从而提高通信效率。

> **练习 2.1**
> 证明在任何最优编码（optimal code）中，若 $p_i > p_j$，则 $l_i \leq l_j$。

我们将在后面的章节中更系统地使用这一原则，以构造任意信息源的最优编码。首先，我们证明：**允许使用唯一可译码（而非瞬时码）的编码方式，不能进一步降低平均编码长度**。因此**将编码限制为瞬时码**上并不会造成任何损失。这一结论可以直接从 §1.6 中的推论 1.22 得出。从而，我们也有以下引理：

> **引理 2.2**  
> 对于给定的信息源 $S$ 和整数 $r$，所有唯一可译 $r$ 进制编码 $C$ 的平均码长 $L(C)$ 的集合，与所有瞬时 $r$ 进制编码 $C$ 的平均码长 $L(C)$ 的集合是相等的。  

这个平均码长的集合显然有下界（最小值至少为 0），因此我们用 $L_{\min}(S)$ 来表示它的**最大下界**（greatest lower bound），这里默认 $r$ 已知。如果一个瞬时 $r$ 进制编码 $C$ 满足 $L(C) = L_{\min}(S)$，则称其为**最优码（optimal code）**。  

然而，最优码的存在性并不是显而易见的。理论上讲，瞬时 $r$ 进制编码的平均码长可能无限接近但永远无法达到最大下界（就像数列 $\frac{1}{n}$ 在 $n \to \infty$ 时趋于 0，但从不等于 0）。因此，我们需要证明**最优码总是存在的**——这是文献中常常被忽略的一个重要点。

> **定理 2.3**  
对于每个信息源 $S$，以及每个 $r \geq 2$ 的整数，都存在一个**最优** $r$ 进制编码。  

**证明**  
如果需要，可以重新编号源符号 $s_1, \dots, s_q$ 。所以，我们假设存在某个整数 $k$，使得：

- 当 $i \leq k$ 时，$p_i > 0$，

- 当 $i > k$ 时，$p_i = 0$。  

设 $p = \min(p_1, \dots, p_k)$，显然有 $p > 0$。  

首先，至少存在一个瞬时 $r$ 进制编码 $C$ 适用于 $S$。例如，可以令 $l_1 = \dots = l_q = l$，其中 $l$ 使得 $r^l \geq q$，然后根据**定理 1.20**构造一个瞬时编码。  

为了证明本定理，只需证明：对于所有瞬时 $r$ 进制编码 $D$，使得 $L(D) \leq L(C)$ 的编码数量是**有限的**。那么这些编码的平均码长 $L(D)$ 也只有有限多个值，其中的最小值一定被某个编码 $D$ 取到，这个 $D$ 就是最优编码。  

为了证明这一点，考虑任意满足 $L(D) \leq L(C)$ 的瞬时 $r$ 进制编码 $D$，其码长 $l_1, \dots, l_q$ 必须满足：

$$
l_i < \frac{L(C)}{p}, \quad \text{对于 } i = 1, \dots, k.
$$  

否则，将导致：

$$
L(D) = p_1 l_1 + \dots + p_q l_q \geq p_i l_i > p \frac{L(C)}{p} = L(C),
$$

这与 $L(D) \leq L(C)$ 矛盾。  

在前述不等式的约束下，只有有限个单词 $w \in T^+$，满足 $ |w| \leq \frac{L(C)}{p} $ ，因此 $D$ 的码字选择 $w_1, \dots, w_k$ 是有限的。对于 $i > k$，码字 $w_i$ 的选取可以有无限多种可能，但由于 $p_i = 0$，这些码字**不会影响** $L(D)$ 的值。因此，$L(D) \leq L(C)$ 的可能取值是有限的，其中的最小值必然可以由某个编码 $D$ 取到，因此最优编码存在。

