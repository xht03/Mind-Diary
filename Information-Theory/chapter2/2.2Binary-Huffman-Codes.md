---
title: "Chapter 2: Optimal Codes (2)"
author: "xht03"
date: 2025-03-12 14:48:30
tags:
- translation
- notes
categories:
- Information and Coding Theory
header-includes:
- \usepackage{xeCJK}
---

## 2.2 Binary Huffman Codes 

1952 年，Huffman 提出了一个用于**构造最优编码**的算法。为简化讨论，我们主要关注**二进制**情况，即令 $T = \mathbb{Z}_2 = \{0,1\}$ 。给定一个信息源 $S$ ，我们首先按照概率大小对符号 $s_1, \dots, s_q$ 进行**重新编号**，使其满足：

$$
p_1 \geq p_2 \geq \dots \geq p_q
$$

然后，我们**合并**概率最小的两个符号 $s_{q-1}$ 和 $s_q$ ，形成一个新的符号：

$$s' = s_{q-1} \vee s_q \quad (\text{表示} s_{q-1} \text{ 或 } s_q)$$

该新符号的概率为：$p' = p_{q-1} + p_q$ 。如果 $s_{q-1}$ 和 $s_q$ 不唯一（即有多个符号满足概率最小），我们就任意选择两个概率最小的符号进行合并。这样，我们就得到了一个新的信息源 $S'$ ，它包含 $q-1$ 个符号：$s_1, \dots, s_{q-2}, s'$ ，对应的概率分布为：$p_1, \dots, p_{q-2}, p'$ 。

给定任何二进制编码 $C'$ 适用于 $S'$ ，我们可以利用 $C'$ 来构造信息源 $S$ 的编码 $C$ ：  

- 如果 $C'$ 对于符号 $s_i$（ $i = 1, \dots, q-2$ ）的编码是 $w_i$，那么 $C$ **沿用**相同的编码。

- 如果 $C'$ 对于合并后的符号 $s'$ 的编码是 $w'$, 则 $C$ 将 $s_{q-1}$ 和 $s_q$ 分别编码为 $w'0$ 和 $w'1$ 。

> **引理 2.4**
> 如果编码 $C'$ 是即时码，那么 $C$ 也是即时码。

**证明**
如果 $C'$ 是一个前缀码，则 $C$ 也是前缀码，这一点很容易验证；由定理 1.17 可完成证明。 $\square$ 

这意味着，对于源 $S$ （具有 $q$ 个符号）的瞬时二进制码 $C$ ，可以从的源 $S'$ （具有 $q - 1$ 个符号）的瞬时二进制码 $C'$ 构造出 。同样，可以从具有 $q - 2$ 个符号的源 $S''$ 的瞬时二进制码 $C''$ 构造出 $S'$ 的瞬时二进制码 $C'$ ，其中 $S''$ 由 $S'$ 通过合并两个最不可能出现的符号得到。  

如果继续按此方式缩减源，我们将得到一系列源：

$$
S \to S' \to \dots \to S^{(q-2)} \to S^{(q-1)}
$$

其符号数量依次减少，最终，$S^{(q-1)}$ 仅包含一个符号 $s_1 \vee \dots \vee s_q$ ，其概率为 1，我们用空字符串 $\epsilon$ 对其进行编码，得到码： $C^{(q-1)} = \{\epsilon\}$ 作为 $S^{(q-1)}$ 的编码。  

随后，通过给一个码字 $w'$ 添加 0 和 1，我们可以得到 $S^{(q-2)}$ 的瞬时二进制码：

$$
C^{(q-2)} = \{c_0 = 0, c_1 = 1\}
$$

重复此过程 $q - 1$ 次，我们最终获得一系列二进制码： $C^{(q-1)}, C^{(q-2)}, \dots, C', C$ ，分别对应源： $S^{(q-1)}, S^{(q-2)}, \dots, S', S$ 。

$$  
S \to S' \to \dots \to S^{(q-2)} \to S^{(q-1)}  
$$  

$$  
C \longleftarrow C' \longleftarrow \dots \longleftarrow C^{(q-2)} \longleftarrow C^{(q-1)}  
$$  

最终得到的码 $C$ 被称为源 $S$ 的 **Huffman 码**。根据 **引理 2.4** 的反复使用，它是一个瞬时码，并且我们将在 §2.4 证明它是最优的。（注意，每个 $C^{(i)}$ 都是 $S^{(i)}$ 的 **Huffman 码**，因为我们可以选择忽略 $s'$ 以及所有 $j < i$ 的 $C^{(j)}$ 码。）

> **例 2.5**  
>
> 设源 $S$ 具有 $q = 5$ 个符号 $s_1, \dots, s_5$ ，其概率分别为 $p_i = 0.3, 0.2, 0.2, 0.2, 0.1$ 。  
>
> 我们首先执行一系列 **源缩减**（source-reduction）操作；其连续的概率分布如下：
>
> |  源  | 概率分布                   |  
> |:----:|:--------------------------|  
> | $S$   | 0.3, 0.2, 0.2, 0.2, 0.1  |  
> | $S'$  | 0.3, **0.3**, 0.2, 0.2   |  
> | $S''$ | **0.4**, 0.3, 0.3        |  
> | $S'''$ | **0.6**, 0.4            |  
> | $S^{(4)}$ | **1**                |
> 
> 在每一行中，我们通过将两个最小的概率替换为它们的和（用**加粗**表示）来形成下一行，并确保新概率集合按非递增顺序排列。然后，我们反向执行此过程，以构造源的哈夫曼编码，从底部的 $S^{(4)}$ 开始，依次向上构造：  
> 
> |    源     |  编码 $C$                  |  
> | :------:  |:--------------------------|  
> |    $C$    | 00, 10, 11, 010, 011      |  
> |    $C'$   | 00, **01**, 10, 11        |  
> |    $C''$  | **1**, 00, 01             |  
> |   $C'''$  | **0**, 1                  |  
> | $C^{(4)}$ | $\varepsilon$             |  
>
> 在反向构造编码时，每一行的编码是从其下一行的编码派生出来的：
> 
> - 对于下行中新合并的符号 $w'$ ，我们在其编码后加上 0 或 1，得到 $w'0, w'1$ ，分别对应合并前的两个符号。  
>
> - 其他编码保持不变。  
> 
> 最终得到的哈夫曼编码为： $C = \{ 00, 10, 11, 010, 011 \}$ 。编码的长度分别为：$l_1 = 2, l_2 = 2, l_3 = 2, l_4 = 3, l_5 = 3$ ，则 $L(C) = \sum P_i l_i = 0.3 \times 2 + 0.2 \times 2 + 0.2 \times 2 + 0.2 \times 3 + 0.1 \times 3 = 2.3$ 。

在大多数情况下，哈夫曼编码的构造过程是唯一的，因此生成的编码也是唯一的（仅在每一步分配 0 或 1 时可有不同选择，但不会影响码长）。然而，如果在某一步骤中有多个最小概率对，则哈夫曼编码可能有多个可能的结果，例如本例中的第一步。这种情况下，尽管编码可能不同，但**平均码长 $L(C)$ 仍然是唯一的**，这是哈夫曼编码的最优性所保证的。

一般来说，概率 $p_i$ 之间的变化越大，最优编码的平均码长就越短。 这是因为在这种情况下，我们有更大的空间为更频繁出现的符号分配更短的编码。我们将在第 3 章中更系统地研究这一现象，并使用**熵（entropy）**这一概念来衡量概率分布中的变化程度。